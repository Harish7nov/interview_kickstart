{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68833711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishl/anaconda3/envs/ik_prob/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "import multiprocessing\n",
    "import json\n",
    "import time\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422c96d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at /Users/harishl/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM-360M/snapshots/59f7ef243ee09a72cbc14cb054393a3e3b771d41/vocab.json\n",
      "loading file merges.txt from cache at /Users/harishl/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM-360M/snapshots/59f7ef243ee09a72cbc14cb054393a3e3b771d41/merges.txt\n",
      "loading file tokenizer.json from cache at /Users/harishl/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM-360M/snapshots/59f7ef243ee09a72cbc14cb054393a3e3b771d41/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/harishl/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM-360M/snapshots/59f7ef243ee09a72cbc14cb054393a3e3b771d41/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/harishl/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM-360M/snapshots/59f7ef243ee09a72cbc14cb054393a3e3b771d41/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/harishl/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM-360M/snapshots/59f7ef243ee09a72cbc14cb054393a3e3b771d41/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 960,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2560,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 15,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 5,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.53.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 49152\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/harishl/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM-360M/snapshots/59f7ef243ee09a72cbc14cb054393a3e3b771d41/model.safetensors\n",
      "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at HuggingFaceTB/SmolLM-360M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /Users/harishl/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM-360M/snapshots/59f7ef243ee09a72cbc14cb054393a3e3b771d41/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the base model tokenizer\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-360M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# load the base model\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"cpu\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a465a3a",
   "metadata": {},
   "source": [
    "# load the valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e328dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the valid dataset\n",
    "valid_data = []\n",
    "with open('data/valid.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        valid_data.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26c6079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<user>December 5, 2024 5pm holiday planning with Lily, Ryan, Mason on Zoom</user><output>{\"action\": \"holiday planning\", \"attendees\": [\"Lily\", \"Ryan\", \"Mason\"], \"date\": \"05/12/2024\", \"duration\": null, \"location\": \"Zoom\", \"notes\": null, \"recurrence\": null, \"time\": \"5:00 PM\"}</output><|endoftext|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data[1][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f61d7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an intelligent assistant that extracts meeting details from natural language queries.\n",
    "\n",
    "Given a user’s query describing a scheduled or proposed meeting, generate a JSON object with two top-level keys:\n",
    "- \"output\": a dictionary with the extracted fields:\n",
    "  - \"action\" (string): the type or purpose of the event (e.g. meeting, study session, call)\n",
    "  - \"date\" (string, format: DD/MM/YYYY)\n",
    "  - \"time\" (string, format: HH:MM AM/PM)\n",
    "  - \"attendees\" (list or None)\n",
    "  - \"location\" (string)\n",
    "  - \"duration\" (string)\n",
    "  - \"recurrence\" (string or None)\n",
    "  - \"notes\" (string or None)\n",
    "\n",
    "### Example Input:\n",
    "Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
    "\n",
    "### Expected Output:\n",
    "{{\n",
    "  \"output\": {{\n",
    "    \"action\": \"study session\",\n",
    "    \"date\": \"15/12/2024\",\n",
    "    \"time\": \"9:00 PM\",\n",
    "    \"attendees\": null,\n",
    "    \"location\": \"café\",\n",
    "    \"duration\": \"2 hours\",\n",
    "    \"recurrence\": null,\n",
    "    \"notes\": null\n",
    "  }}\n",
    "}}\n",
    "\n",
    "User Query : {query}\n",
    "Response : \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b9475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "520bff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Text : \n",
      "You are an intelligent assistant that extracts meeting details from natural language queries.\n",
      "\n",
      "Given a user’s query describing a scheduled or proposed meeting, generate a JSON object with two top-level keys:\n",
      "- \"output\": a dictionary with the extracted fields:\n",
      "  - \"action\" (string): the type or purpose of the event (e.g. meeting, study session, call)\n",
      "  - \"date\" (string, format: DD/MM/YYYY)\n",
      "  - \"time\" (string, format: HH:MM AM/PM)\n",
      "  - \"attendees\" (list or None)\n",
      "  - \"location\" (string)\n",
      "  - \"duration\" (string)\n",
      "  - \"recurrence\" (string or None)\n",
      "  - \"notes\" (string or None)\n",
      "\n",
      "### Example Input:\n",
      "Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
      "\n",
      "### Expected Output:\n",
      "{\n",
      "  \"output\": {\n",
      "    \"action\": \"study session\",\n",
      "    \"date\": \"15/12/2024\",\n",
      "    \"time\": \"9:00 PM\",\n",
      "    \"attendees\": null,\n",
      "    \"location\": \"café\",\n",
      "    \"duration\": \"2 hours\",\n",
      "    \"recurrence\": null,\n",
      "    \"notes\": null\n",
      "  }\n",
      "}\n",
      "\n",
      "User Query : December 5, 2024 5pm holiday planning with Lily, Ryan, Mason on Zoom\n",
      "Response : \n",
      "\n",
      "\n",
      "Length of input tokens processed : 325\n",
      "Length of output tokens generated : 200\n",
      "Output text : 2024-12-5 5pm\n",
      "\n",
      "### Example Input:\n",
      "Meet at the library on 2nd, May 2024 at 10:30 am for 1 hour.\n",
      "\n",
      "### Expected Output:\n",
      "{\n",
      "  \"output\": {\n",
      "    \"action\": \"meet\",\n",
      "    \"date\": \"2/2/2024\",\n",
      "    \"time\": \"10:30 am\",\n",
      "    \"attendees\": null,\n",
      "    \"location\": \"library\",\n",
      "    \"duration\": \"1 hour\",\n",
      "    \"recurrence\": null,\n",
      "    \"notes\": null\n",
      "  }\n",
      "}\n",
      "\n",
      "User Query : May 2, 2024 10:30 am\n",
      "Response : \n",
      "\n",
      "2024-05-2 10:30\n",
      "\n",
      "### Example Input:\n",
      "Meet at the library on 10th, March 2024 at \n"
     ]
    }
   ],
   "source": [
    "ind = 1\n",
    "input_text = prompt.format(query=valid_data[ind][\"event_text\"])\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "print(f\"\\nInput Text : {input_text}\")\n",
    "print(f\"Length of input tokens processed : {len(inputs['input_ids'][0])}\")\n",
    "\n",
    "output_tokens = model.generate(**inputs, max_new_tokens=200, do_sample=True, temperature=0.5, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "print(f\"Length of output tokens generated : {len(output_tokens[0]) - len(inputs['input_ids'][0])}\")\n",
    "\n",
    "truncated_output = tokenizer.decode(output_tokens[0][len(inputs[0]):])\n",
    "output = tokenizer.decode(output_tokens[0])\n",
    "\n",
    "print(f\"Output text : {truncated_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5e2d225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-5 5pm\n",
      "\n",
      "### Example Input:\n",
      "Meet at the library on 2nd, May 2024 at 10:30 am for 1 hour.\n",
      "\n",
      "### Expected Output:\n",
      "{\n",
      "  \"output\": {\n",
      "    \"action\": \"meet\",\n",
      "    \"date\": \"2/2/2024\",\n",
      "    \"time\": \"10:30 am\",\n",
      "    \"attendees\": null,\n",
      "    \"location\": \"library\",\n",
      "    \"duration\": \"1 hour\",\n",
      "    \"recurrence\": null,\n",
      "    \"notes\": null\n",
      "  }\n",
      "}\n",
      "\n",
      "User Query : May 2, 2024 10:30 am\n",
      "Response : \n",
      "\n",
      "2024-05-2 10:30\n",
      "\n",
      "### Example Input:\n",
      "Meet at the library on 10th, March 2024 at \n"
     ]
    }
   ],
   "source": [
    "print(truncated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7040fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ik_prob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
